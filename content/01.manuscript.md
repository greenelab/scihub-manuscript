## Introduction {.page_break_before}

Recent estimates suggest paywalls on the web limit access to three-quarters of scholarly literature [@doi:10.7287/peerj.preprints.3119v1; @doi:10.1371/journal.pone.0093949].
The open access movement strives to remedy this situation [@doi:10.12688/f1000research.8460.3].
After decades of effort by the open access community [@url:http://digitalcommons.unl.edu/library_talks/123], nearly 50% of newly published articles are available without paywalls [@doi:10.7287/peerj.preprints.3119v1; @url:http://digitalcommons.unl.edu/scholcom/8; @doi:10.1038/500386a].

Despite these gains, access to scholarly literature remains a pressing global issue.
Foremost, widespread subscription access remains restricted to institutions, such as universities or medical centers.
Smaller institutions or those in the developing world often have poor access to scholarly literature [@doi:10.3998/3336451.0018.301 @doi:10.1080/00987913.2005.10764998 @doi:10.1108/03074800510587354].
As a result, only a tiny percentage of the world's population has been able to access much of the scholarly literature, despite the fact that the underlying research was often publicly or philanthropically funded.
Compounding the problem is that publications have historically been the primary, if not sole, output of scholarship.
Although copyright does not apply to ideas, journals leverage the copyright covering an article's prose, figures, and typesetting to effectively paywall its knowledge, as other routes to consuming the knowledge do not exist.

Since each article is unique, libraries cannot substitute one journal subscription for another without depriving their users of potentially crucial access.
As a result, the price of journal subscriptions has grown at a faster rate than inflation for several decades, leading to an ever-present "serials crisis" that has pushed library budgets to their brink while diverting funds from other services [@doi:10.1300/J123v18n01_09].
Meanwhile, publishing has trended towards oligopoly [@doi:10.1371/journal.pone.0127502], with nondisclosure clauses obfuscating price information [@doi:10.1073/pnas.1403006111].
Price increases have persisted over the last decade [@url:http://lj.libraryjournal.com/2017/04/publishing/new-world-same-model-periodicals-price-survey-2017/; @doi:10.6084/m9.figshare.1186832.v23; @doi:10.6084/m9.figshare.4542433.v6].
However, a tipping point may be near.
In the last year, negotiations between libraries and major publishers have broken down, leaving entire countries without access [@doi:10.1038/nature.2016.21223; @doi:10.1126/science.aal0552; @url:https://www.timeshighereducation.com/news/dutch-lose-access-oup-journals-subscription-standoff].

Literature that is free to read is comprised of two categories [@url:https://dash.harvard.edu/handle/1/4322580].
The first category includes articles that are [openly licensed](http://opendefinition.org/) to freely allow reuse, a group colloquially termed "free as in libre".
The remainder of free to read articles can be accessed without price barriers, but permission barriers may remain (usually due to copyright) [@url:http://blog.dhimmel.com/biorxiv-licenses/].
This set of articles is termed "free as in gratis".
In this work, we refer to availability as "libre" or "gratis" to denote these categories.

The website Sci-Hub, now in its fifth year of existence, provides gratis access to scholarly literature, despite the continued presence of paywalls.
Sci-Hub brands itself as "the first pirate website in the world to provide mass and public access to tens of millions of research papers."
The website, started in 2011, is run by Alexandra Elbakyan, a graduate student and native of Kazakhstan who now resides in Russia [@doi:10.1126/science.aaf5675; @doi:10.1038/nature.2015.18876].
Elbakyan describes herself as motivated to provide universal access to knowledge [@url:https://engineuring.wordpress.com/2016/03/11/sci-hub-is-a-goal-changing-the-system-is-a-method/; @url:https://www.courtlistener.com/docket/4355308/50/elsevier-inc-v-sci-hub/; @url:http://www.leafscience.org/alexandra-elbakyan/].

Sci-Hub does not restrict itself to only openly licensed content.
Instead, it retrieves and distributes scholarly literature without regard to copyright regimes.
**Readers should note that, in many jurisdictions, use of Sci-Hub may constitute copyright infringement.
Users of Sci-Hub do so at their own risk.
This study is not an endorsement of using Sci-Hub, and its authors and publishers accept no responsibility on behalf of readers.
There is a possibility that Sci-Hub users — especially those not using privacy-enhancing services such as Tor — could have their usage history unmasked and face consequences, both legal or reputational in nature.**

Sci-Hub is currently served at domains including `sci-hub.cc`, `sci-hub.io`, `sci-hub.ac`, and `sci-hub.bz`, as well as at `scihub22266oqcxt.onion` — a Tor Hidden Service [@url:http://www.dtic.mil/docs/citations/ADA465464].
Elbakyan described the project's technical scope in July 2017 [@url:https://engineuring.wordpress.com/2017/07/02/some-facts-on-sci-hub-that-wikipedia-gets-wrong/]:

> Sci-Hub technically is by itself a repository, or a library if you like, and not a search engine for some other repository.
But of course, the most important part in Sci-Hub is not a repository, but the script that can download papers closed behind paywalls.

One method Sci-Hub uses to bypass paywalls is by obtaining leaked authentication credentials for educational institutions [@url:https://engineuring.wordpress.com/2017/07/02/some-facts-on-sci-hub-that-wikipedia-gets-wrong/].
These credentials enable Sci-Hub to use institutional networks as proxies and gain subscription journal access.
While the open access movement has progressed slowly [@doi:10.1007/s12525-017-0249-2], Sci-Hub represents a seismic shift in access to scholarly literature.
Since its inception, Sci-Hub has experienced sustained growth, with spikes in interest and awareness driven by legal proceedings, news coverage, and social media (Figure @fig:history).
Here we investigate the extent to which Sci-Hub provides access to scholarly literature.
If Sci-Hub's coverage is sufficiently broad, then a radical shift may be underway in how individuals access scholarly literature.

![
**The history of Sci-Hub.**
Weekly interest from Google Trends is plotted over time for the search terms "Sci-Hub" and "LibGen".
The light green period indicates when Sci-Hub used LibGen as its database for storing articles [@url:https://engineuring.wordpress.com/2017/07/02/some-facts-on-sci-hub-that-wikipedia-gets-wrong/].
The light blue period indicates the public availability of access logs from Sci-Hub [@doi:10.5061/dryad.q447c/1].
The first pink dotted line represents the collection date of the LibGen metadata used in Cabanac's study [@doi:10.1002/asi.23445; @doi:10.6084/m9.figshare.4906367.v1].
The second pink dotted line shows the date of Sci-Hub's Tweeted DOI catalog used in this study.
](https://cdn.rawgit.com/greenelab/scihub/6c6d19a56a0371afe6131c7948c406f256b8742c/explore/trends/google-trends.svg){#fig:history}

In Figure @fig:history, The ⓛⓔⓣⓣⓔⓡⓢ refer to the following events:

+ **Ⓐ** Created by Alexandra Elbakyan, the Sci-Hub website goes live on September 5, 2011.
+ **Ⓑ** Several LibGen domains go down when their registration expires, allegedly due to a longtime site administrator passing away from cancer [@url:https://redd.it/2raea8].
+ **Ⓒ** Elsevier files a civil suit against Sci-Hub and LibGen — at the respective domains `sci-hub.org` and `libgen.org` —  in the U.S. District Court for the Southern District of New York [@url:https://torrentfreak.com/elsevier-cracks-down-on-pirated-scientific-articles-150609/; @url:https://www.courtlistener.com/docket/4355308/1/elsevier-inc-v-sci-hub/].
The complaint seeks a "prayer for relief" that includes domain name seizure, damages, and "an order disgorging Defendants' profits".
+ **Ⓓ** Elsevier is granted a preliminary injunction to suspend domain names and restrain the site operators from distributing Elsevier's copyrighted works [@url:https://torrentfreak.com/court-orders-shutdown-of-libgen-bookfi-and-sci-hub-151102/; @url:https://www.courtlistener.com/docket/4355308/53/elsevier-inc-v-sci-hub/].
Shortly after, Sci-Hub and LibGen resurface at alternative domains outside of U.S. court jurisdiction, including on the dark web [@url:https://torrentfreak.com/sci-hub-and-libgen-resurface-after-being-shut-down-151121/; @doi:10.1038/nature.2015.18876].
+ **Ⓔ** The article "Meet the Robin Hood of Science" by Simon Oxenham spurs a wave of attention and news coverage on Sci-Hub and Alexandra Elbakyan [@url:http://bigthink.com/neurobonkers/a-pirate-bay-for-science], culminating in _The New York Times_ asking "Should all research papers be free?" [@url:https://www.nytimes.com/2016/03/13/opinion/sunday/should-all-research-papers-be-free.html].
+ **Ⓕ** The article "Who's downloading pirated papers? Everyone" by John Bohannon shows Sci-Hub is used worldwide, including in developed countries [@doi:10.1126/science.352.6285.508; @doi:10.1126/science.aaf5664].
These findings spark debate among scholars, with a large contingent of scientists supporting Sci-Hub's mission [@doi:10.1038/nature.2016.19841; @doi:10.1126/science.aaf5704].
+ **Ⓖ** Alexandra Elbakyan is named one of "_Nature_'s 10", which featured "ten people who mattered" in 2016 [@doi:10.1038/540507a].
Written by Richard Van Noorden, the story profiles Alexandra and includes an estimate that Sci-Hub serves "3% of all downloads from science publishers worldwide."
+ **Ⓗ** The court finds that Alexandra Elbakyan, Sci-Hub, and LibGen are "liable for willful copyright infringement" in a default judgment, since none of the defendants answered Elsevier's complaint [@doi:10.1038/nature.2017.22196; @url:https://torrentfreak.com/sci-hub-ordered-to-pay-15-million-in-piracy-damages-170623/; @url:https://www.documentcloud.org/documents/3878258-2017-06-21-Elsevier-Sci-Hub-Final-Judgement.html].
The court issues a permanent injunction and orders the defendants to pay Elsevier $15 million, or $150,000 for each of 100 copyrighted works.
The statutory damages, which the defendants do not intend to pay, now bear interest.
+ **Ⓘ** The American Chemical Society files suit against Sci-Hub in the U.S. District Court for the Eastern District of Virginia.
Their "prayer for relief" requests that Internet search engines and Internet service providers "cease facilitating access" to Sci-Hub [@url:https://torrentfreak.com/new-lawsuit-demands-isp-blockades-against-pirate-site-sci-hub-170629/; @url:https://www.documentcloud.org/documents/3879464-2017-06-23-ACS-Sci-Hub-Complaint.html].
+ **Ⓙ** The version 1 preprint of this study is published [@doi:10.7287/peerj.preprints.3100v1], generating headlines such as _Science_'s "subscription journals are doomed" [@doi:10.1126/science.aan7164] and _Inside Higher Ed_'s "Inevitably Open" [@url:https://www.insidehighered.com/blogs/library-babel-fish/inevitably-open].
+ **Ⓚ** Sci-Hub blocks access to Russian IP addresses due to disputes with the Russian Scientific establishment and the naming of a newly discovered parasitoid wasp species, _Idiogramma elbakyanae_, after Alexandra Elbakyan [@url:http://foreignpolicy.com/2017/09/06/the-worlds-largest-free-scientific-resource-is-now-blocked-in-russia/ @doi:10.3897/jhr.58.12919].
Four days later, Sci-Hub restores access after receiving "many letters of support from Russian researchers" [@url:http://alla-astakhova.ru/sci-hub/].

Past research sheds some light on Sci-Hub's reach.
From the Spring of 2013 until the end of 2014, Sci-Hub relied on the Library Genesis (LibGen) scimag repository to store articles [@url:https://engineuring.wordpress.com/2017/07/02/some-facts-on-sci-hub-that-wikipedia-gets-wrong/].
Whenever a user requested an article, Sci-Hub would check LibGen for a copy.
If the article was not in LibGen, Sci-Hub would fetch the article for the user and then upload it to LibGen.
Cabanac compared the number of articles in the LibGen scimag database at the start of 2014 to the total number of Crossref DOIs, estimating that LibGen contained 36% of all published scholarly articles [@doi:10.1002/asi.23445].
Coverage was higher for several prominent publishers: 77% for Elsevier, 73% for Wiley, and 53% for Springer (prior to its merger with Macmillan / Nature [@doi:10.1038/nature.2015.16731]).

Later, Bohannon analyzed six months of Sci-Hub's server access logs, starting in September 2015 [@doi:10.1126/science.352.6285.508].
He found a global pattern of usage.
Based on these logs, Gardner, McLaughlin, and Asher estimated the ratio of publisher downloads to Sci-Hub downloads within the U.S. for several publishers [@url:https://hdl.handle.net/10760/30981].
They estimated this ratio at 20:1 for the Royal Society of Chemistry and 48:1 for Elsevier.
They also noted that 25% of article downloads in the U.S. are in fields related to clinical medicine.
Greshake also analyzed the logs to identify per capita Sci-Hub usage [@doi:10.15200/winn.146485.57797].
Portugal, Iran, Tunisia, and Greece had the highest usage, suggesting Sci-Hub is preferentially used in countries with poor institutional access to scholarly literature.
In a subsequent study, Greshake found especially high Sci-Hub usage in chemistry, with 12 of the top 20 requested journals specializing in chemistry [@doi:10.12688/f1000research.11366.1; @doi:10.5281/zenodo.472493].

Since 2015, Sci-Hub has operated its own repository, distinct from LibGen.
On March 19, 2017, Sci-Hub released the list of DOIs for articles in its database.
Greshake retrieved metadata for 77% of Sci-Hub DOIs [@doi:10.12688/f1000research.11366.1; @doi:10.5281/zenodo.472493].
He found that 95% of articles in Sci-Hub were published after 1950.
Sci-Hub requests were even more skewed towards recent articles, with only 5% targeting articles published before 1983.
Greshake's study did not incorporate a catalog of all scholarly literature.
This study analyzes Sci-Hub's catalog in the context of all scholarly literature and thus assesses coverage.
In other words, what percentage of articles in a given domain does Sci-Hub have in its repository?

## Results {.page_break_before}

To define the extent of the scholarly literature, we relied on DOIs from the Crossref database, as downloaded on March 21, 2017.
We define the "scholarly literature" as 81,609,016 texts identified by their DOIs.
We refer to these texts as "articles", although Sci-Hub encompasses a range of text types, including book chapters, conference papers, and journal front matter.
To assess the articles available from Sci-Hub, we relied on a list of DOIs released by Sci-Hub on March 19, 2017.
All DOIs were lowercased to be congruent across datasets (see Methods).
Sci-Hub's offerings included 56,246,220 articles from the corpus of scholarly literature, equating to 68.9% of all articles.

### Coverage by article type

Each article in Crossref's database is assigned a type.
Figure @fig:types shows coverage by article type.
The scholarly literature consisted primarily of journal articles, for which Sci-Hub had 77.8% coverage.
Sci-Hub's coverage was also strong for the 5 million proceedings articles at 79.7%.
Overall coverage suffered from the 10 million book chapters, where coverage was poor (14.2%).
The remaining Crossref types were uncommon, and hence contributed little to overall coverage.

![
**Coverage by article type.**
Coverage is plotted for the Crossref work types included by this study.
We refer to all of these types as "articles".
](https://cdn.rawgit.com/greenelab/scihub/6c6d19a56a0371afe6131c7948c406f256b8742c/figure/coverage-by-type.svg){#fig:types width="4in"}

### Coverage by journal

We defined a comprehensive set of scholarly publishing venues, referred to as "journals", based on the Scopus database.
In reality, these include conferences with proceedings as well as book series.
For inclusion in this analysis, each required an ISSN and at least one article as part of the Crossref-derived catalog of scholarly literature.
Accordingly, our catalog consisted of 22,193 journals encompassing 57,074,208 articles.
Of these journals, 4,345 (19.6%) were inactive (i.e. no longer publishing articles), and 2,650 were open access (11.9%).
Only two journals were inactive and also open access.

We calculated Sci-Hub's coverage for each of the 22,193 journals (examples in Table @tbl:top-ten-journals).
The complete journal coverage results are available in our [Sci-Hub Stats Browser](https://greenelab.github.io/scihub/#/journals).

| Journal | Sci-Hub | Crossref | Coverage |
|-------|--------|----------|----------|
| The Lancet | 457,650 | 458,580 | 99.80% |
| Nature | 385,619 | 399,273 | 96.58% |
| BMJ (Clinical research ed.) | 17,141 | 392,277 | 4.37% |
| Lecture Notes in Computer Science | 103,675 | 356,323 | 29.10% |
| Science | 230,649 | 251,083 | 91.86% |
| JAMA - Journal of the American Medical Association | 191,950 | 248,369 | 77.28% |
| Journal of the American Chemical Society | 189,142 | 189,567 | 99.78% |
| Scientific American | 22,600 | 186,473 | 12.12% |
| New England Journal of Medicine | 180,321 | 180,467 | 99.92% |
| PLoS ONE | 4,731 | 177,260 | 2.67% |

Table: **Coverage for the ten journals with the most articles.**
{#tbl:top-ten-journals}

In general, a journal's coverage was either nearly complete or nearly entirely absent (Figure @fig:distributions).
As a result, relatively few journals had coverage between 5–75%.
At the extremes, 2,342 journals had zero coverage in Sci-Hub, whereas 2,067 journals had perfect coverage.
Of zero-coverage journals, 22.3% were inactive, and 27.2% were open access.
Of perfect-coverage journals, 80.3% were inactive, and 1.9% were open access.
Hence, inactive, closed-access journals make up the bulk of perfect-coverage journals.

![
**Distributions of journal & publisher coverages.**
The histograms show the distribution of Sci-Hub's coverage for journals and publishers.
Each bin spans 2.5 percentage points.
](https://cdn.rawgit.com/greenelab/scihub/6c6d19a56a0371afe6131c7948c406f256b8742c/figure/coverage-distributions.svg){#fig:distributions width="5in"}

Next, we explored article coverage according to journal attributes (Figure @fig:attributes).
Sci-Hub covered 83.4% of the 57,074,208 articles that were attributable to an academic journal.
Articles from inactive journals had slightly lower coverage than active journals (77.0% versus 84.3%).
Strikingly, coverage was substantially higher for articles from closed- rather than open-access journals (85.2% versus 49.1%).
Coverage did vary by subject area, with the highest coverage in chemistry at 92.8% and the lowest coverage in computer science at 76.3%.
Accordingly, no discipline had coverage below 75%.
See Figure @fig:countries for coverage according to a journal's country of publication.

![
**Coverage by journal attributes.**
Coverage was assessed for all articles from journals with the specified Scopus attributes.
](https://cdn.rawgit.com/greenelab/scihub/6c6d19a56a0371afe6131c7948c406f256b8742c/figure/coverage.svg){#fig:attributes}

We also evaluated whether journal coverage varied by journal impact.
We assessed journal impact using the 2015 CiteScore, which measures the average number of citations that articles published in 2012–2014 received during 2015.
Highly cited journals tended to have higher coverage in Sci-Hub (Figure {@fig:citescore}A).
The 1,730 least cited journals (lowest decile) had 40.9% coverage on average, whereas the 1,729 most cited journals (top decile) averaged 90.3% coverage.

### Coverage by publisher

Next, we evaluated coverage by publisher (Figure @fig:publishers, full table [online](https://greenelab.github.io/scihub/#/publishers)).
The largest publisher was Elsevier, with 13,185,971 articles from 3,356 journals.
Sci-Hub covered 97.3% of Elsevier articles.
For the eight publishers with more than one million articles, the following coverage was observed:
97.3% of Elsevier,
89.4% of Springer Nature,
94.8% of Wiley-Blackwell,
96.2% of Taylor & Francis,
79.2% of Wolters Kluwer,
98.8% of American Chemical Society,
95.3% of SAGE, and
84.9% of Oxford University Press.
In total, 4,878 publishers were represented in the journal catalog.
The coverage distribution among publishers resembled the journal coverage distribution, with most publishers occupying the extremities (Figure @fig:distributions).
Sci-Hub had zero coverage for 1,206 publishers, and complete coverage for 323 publishers.

![
**Coverage by publisher.**
Article coverage is shown for all Scopus publishers with at least 200,000 articles.
](https://cdn.rawgit.com/greenelab/scihub/6c6d19a56a0371afe6131c7948c406f256b8742c/figure/coverage-by-publisher.svg){#fig:publishers}

### Coverage by year

Next, we investigated coverage based on the year an article was published (Figure @fig:years).
For most years since 1850, annual coverage is between 60–80%.
However, there is a dropoff in coverage, starting in 2010, for recently published articles.
For example, 2016 coverage was 56.0% and 2017 coverage (for part of the year) was 45.3%.
One factor is that it can take some time for Sci-Hub to retrieve articles following their publication, as many articles are not downloaded until requested by a user.
Another possible factor is that some publishers are now deploying more aggressive measures to deter unauthorized article downloads [@url:http://cen.acs.org/articles/92/web/2014/04/Online-Access-ACS-Publications-Restored.html; @doi:10.1038/535011f], making recent articles less accessible.

![
**Coverage of articles by year published.**
Sci-Hub's article coverage is shown for each year since 1850.
](https://cdn.rawgit.com/greenelab/scihub/6c6d19a56a0371afe6131c7948c406f256b8742c/figure/coverage-by-year.svg){#fig:years}

In addition, the prevalence of open access has been increasing, while Sci-Hub preferentially covers articles in closed access journals.
Figure @fig:years-by-access tracks yearly coverage separately for articles in closed and open access journals.
Closed access coverage exceeded 80% every year since 1950 except for 2016 and 2017.
For both closed and open articles, the recent dropoff in coverage appears to begin in 2014 (Figure @fig:years-by-access) compared to 2010 when calculated across all articles (Figure @fig:years).
We speculate this discrepancy results from the proliferation of obscure, low-quality journals over the last decade [@doi:10.1186/s12916-015-0469-2], as these journals generally issue DOIs but are not indexed in Scopus, and therefore would be included in Figure @fig:years but not in Figure @fig:years-by-access.
In addition to having limited readership demand, these journals are generally open access, and thus less targeted by Sci-Hub.

![
**Coverage of articles by year published and journal access status.**
Sci-Hub's coverage is shown, separately for articles in open versus closed access journals, for each year since 1950.
](https://cdn.rawgit.com/greenelab/scihub/6c6d19a56a0371afe6131c7948c406f256b8742c/figure/coverage-by-year-and-access.svg){#fig:years-by-access}

Sci-Hub's coverage of 2016 articles in open access journals was just 32.8% compared to 79.1% for articles in closed access journals (Figure @fig:years-by-access).
Upon further investigation, we discovered that in June 2015, Sci-Hub ceased archiving articles in _PeerJ_, _eLife_, and PLOS journals, although they continued archiving articles in other open access journals such as _Scientific Reports_, _Nature Communications_, and BMC-series journals (`13.oa-journal-dropoffs.ipynb`).
Sci-Hub currently redirects requests for these delisted journals to the publisher's site, unless it already possesses the article, in which case it serves the PDF.
These findings are consistent with an explicit decision by Sci-Hub to prioritize its resources on circumventing access barriers rather than creating a single repository containing every scholarly article.

### Coverage by category of access status

In the previous analyses, open-access status was determined at the journal level according to Scopus.
This category of access is frequently referred to as "gold" open access, meaning that all articles from the journal are available gratis.
However, articles in closed-access journals may also be available without charge.
Adopting the terminology from the recent "State of OA" study [@doi:10.7287/peerj.preprints.3119v1], articles in closed-access journals may be available gratis from the publisher under a license that permits use (termed "hybrid") or with all rights reserved (termed "bronze").
Alternatively, "green" articles are paywalled on the publisher's site, but available gratis from an open access repository (e.g. a pre- or post-print server, excluding Sci-Hub and academic social networks).

The State of OA study compiled three collections of articles (see [Methods](#state-of-oa-datasets)) and assigned each article an access status using their oaDOI utility.
Figure {@fig:state-of-oa}A shows Sci-Hub's coverage for each category of access status.
In line with our findings on the entire Crossref article catalog where Sci-Hub covered 49.1% of articles in open-access journals, Sci-Hub's coverage on gold articles in the State of OA's Crossref collection was 47.8%.
Impressively, Sci-Hub's coverage of the closed articles in the Web of Science collection was 97.8%.
This remarkable coverage likely reflects that these articles were published from 2009–2015 and classified as citable items by Web of Science, which is selective when indexing journals [@doi:10.1007/s11192-015-1765-5].

For all three collections, Sci-Hub's coverage was higher for closed and green articles than for hybrid or bronze articles. 
Furthermore, Sci-Hub's coverage of closed articles was similar to its coverage of green articles (Figure {@fig:state-of-oa}A).
These findings suggest a historical pattern where users resort to Sci-Hub after encountering a paywall but before checking oaDOI or a search engine for green access.
As such, Sci-Hub receives requests for green articles, triggering it to retrieve green articles at a similar rate to closed articles.
However, hybrid and bronze articles, which are available gratis from their publisher, are requested and thus retrieved at a lower rate.

![
**Coverage on the State of OA datasets.**
**A)** Sci-Hub's coverage by category of oaDOI access type.
Color indicates accessibility status.
Gray indicates closed (not accessible via oaDOI).
**B)** Coverage of oaDOI, Sci-Hub, and the combination of both repositories.
](https://cdn.rawgit.com/greenelab/scihub/6c6d19a56a0371afe6131c7948c406f256b8742c/figure/state-of-oa.svg){#fig:state-of-oa}

### oaDOI Coverage

[oaDOI](https://oadoi.org/) is a utility that redirects paywalled DOIs to gratis, licit versions, when possible [@doi:10.7287/peerj.preprints.3119v1].
Like Sci-Hub, oaDOI is used to find gratis access to fulltext scholarly articles.
Figure {@fig:state-of-oa}B shows oaDOI's coverage on the three State of OA article collections.
Note that oaDOI has complete coverage of all access categories besides closed, where it has zero coverage.
Alone oaDOIs coverage is limited: below 50% on every collection due to the large number of closed articles where it could not locate gratis access.
However, oaDOI's coverage greatly complements Sci-Hub's coverage, with combined coverage exceeding 89% for each of the three collections.
On the Web of Science collection, combining Sci-Hub's 92.9% coverage with oaDOIs 36.0% coverage yielded 98.6% coverage.
On the Unpaywall collection, which best reflects the access needs of contemporary scholars, combined coverage was 94.1%.
In short, deficits in Sci-Hub's coverage are largely made up for when considering licit access routes.

### Coverage of recently cited articles

The coverage metrics presented thus far give equal weight to each article.
However, we know that article readership and by extension Sci-Hub requests are not uniformly distributed across all articles.
Instead, most articles receive little readership, with a few articles receiving great readership.
Therefore, we used recent citations to estimate Sci-Hub's coverage of articles weighted by user needs.

We identified 7,312,607 outgoing citations from articles published since 2015.
6,657,410 of the recent citations (91.0%) referenced an article that is in Sci-Hub.
However, if only considering the 6,252,279 citations to articles in closed-access journals, Sci-Hub covers 96.2% of recent citations.
On the other, for the 858,583 citations to articles in open-access journals, Sci-Hub's covers only 62.4%.

### Sci-Hub access logs

Sci-Hub has released article access records from its server logs, covering 165 days from September 2015 through February 2016 [@doi:10.1126/science.352.6285.508; @doi:10.1126/science.aaf5664; @doi:10.5061/dryad.q447c/1].
After processing, the logs contained 26,984,851 access events.
Hence, Sci-Hub provided access to an average of 164,000 requests per day in late 2015–early 2016.

In the first version of this study [@doi:10.7287/peerj.preprints.3100v1], we mistakenly treated the log events as requests rather than downloads.
Fortunately, Sci-Hub reviewed the preprint in a [series of tweets](https://github.com/greenelab/scihub-manuscript/issues/17), and pointed out the error, stating:

> in Sci-Hub access logs released previous year, all requests are resolved requests, i.e. user successfully downloaded PDF with that DOI … unresolved requests are not saved

Interestingly however, 198,600 access events from the logs pointed to DOIs that were not in Sci-Hub's subsequent DOI catalog.
99.1% of these events — corresponding to DOIs logged as accessed despite later being absent from Sci-Hub — were for book chapters.
Upon further investigation, we [identified](https://github.com/greenelab/scihub-manuscript/issues/20#issuecomment-327854780) several DOIs in this category that Sci-Hub redirected to LibGen book records as of September 2017.
The LibGen landing pages were for the entire books, which contained the queried chapters, and were part of LibGen's book (not scimag) collection.
The explanation that Sci-Hub outsources some book access to LibGen (and logged such requests as accessed) is corroborated by Elbakyan's statement that [@url:https://engineuring.wordpress.com/2017/07/02/some-facts-on-sci-hub-that-wikipedia-gets-wrong/]:
 
> Currently, the Sci-Hub does not store books, for books users are redirected to LibGen, but not for research papers.
In future, I also want to expand the Sci-Hub repository and add books too.

Nonetheless, Sci-Hub's catalog contains 72.4% of the 510,760 distinct book chapters that were accessed according to the logs.
Therefore, on a chapter-by-chapter basis, Sci-Hub does already possess many of the requested scholarly books available from LibGen.

We computed journal-level metrics based on average article downloads.
The "visitors" metric assesses the average number of IP addresses that accessed each article published by a journal during the 20 months preceding September 2015 (the start date of the Sci-Hub logs).
In aggregate, articles from closed access journals averaged 1.30 visitors, whereas articles from open access journals averaged 0.27 visitors.
Figure {@fig:citescore}B shows that articles from highly cited journals were visited much more frequently on average.
Articles in the least cited closed access journals averaged almost zero visitors, compared to approximately 15 visitors for the most cited journals.
In addition, Figure {@fig:citescore}B shows that articles in closed access journals received many times more visitors than those in open access journals, even after accounting for journal impact.
One limitation of using this analysis to judge Sci-Hub's usage patterns is that we do not know to what extent certain categories of articles were resolved (and thus logged) at different rates.

![
**Relation to journal impact.**
**A)**
Average coverage for journals divided into 2015 CiteScore deciles.
The CiteScore range defining each decile is shown by the x-axis labels.
The ticks represent 99% confidence intervals of the mean.
This is the only analysis where "Sci-Hub Coverage" refers to journal-level rather than article-level averages.
**B)**
The association between 2015 CiteScore and average visitors per article is plotted for open and closed access journals.
Curves show the 95% confidence band from a Generalized Additive Model.
](https://cdn.rawgit.com/greenelab/scihub/6c6d19a56a0371afe6131c7948c406f256b8742c/figure/citescore.svg){#fig:citescore}

## Discussion {.page_break_before}

Sci-Hub's repository contains 69% of all scholarly articles with DOIs.
Coverage for the 54.3 million articles attributed to closed access journals — which some users may not otherwise be able to access — was 85.2%.
Since Sci-Hub can retrieve, in real time, requested articles that are not in its database, our coverage figures are a lower bound.
Furthermore, Sci-Hub preferentially covers popular, paywalled articles.
We find that citations since 2015 were 91.0% present in Sci-Hub's repository, which increased to 96.2% when excluding citations to articles in open-access journals.
Journals with very low (including zero) coverage tended to be obscure, less cited venues, while coverage of the most cited journals exceeded 90%.

We find strong evidence that Sci-Hub is primarily used to circumvent paywalls.
In particular, users accessed articles from closed access journals much more frequently than open access journals.
Additionally, within closed-access journals, Sci-Hub provided higher coverage of articles in the closed and green categories (paywalled by the publisher) as opposed to the hybrid and bronze categories (available gratis from the publisher).
Accordingly, many users likely only resort to Sci-Hub when access through a commercial database is cumbersome or costly.
Finally, we observed evidence that Sci-Hub's primary operational focus is circumventing paywalls rather than compiling all literature, as archiving was deactivated in 2015 for several journals that exemplify openness.

Judging from donations, many users appear to value Sci-Hub's service.
In the past, Sci-Hub accepted donations through centralized and regulated payment processors such as PayPal, Yandex, WebMoney, and QiQi [@url:https://www.courtlistener.com/docket/4355308/1/elsevier-inc-v-sci-hub/; @url:https://www.courtlistener.com/docket/4355308/8/23/elsevier-inc-v-sci-hub/].
Now however, Sci-Hub only advertises donation via Bitcoin, presumably to avoid banking blockades or government seizure of funds.
Since the ledger of bitcoin transactions is public, we can evaluate the donation activity to known Sci-Hub addresses (`1K4t2vSBSS2xFjZ6PofYnbgZewjeqbG1TM`, `14ghuGKDAPdEcUQN4zuzGwBUrhQgACwAyA`, `1EVkHpdQ8VJQRpQ15hSRoohCztTvDMEepm`).
We find that as of September 26, 2017, these addresses have received 1,128 donations, totaling 93.94 bitcoins (Figure @fig:bitcoin, Figure @fig:bitcoin-all).
Using the U.S. dollar value at the time of transaction confirmation, Sci-Hub has received an equivalent of $64,455 in bitcoins.
However, since the price of bitcoins has risen, the 68.48 donated bitcoins that remain unspent are now worth approximately $268,000.
In response to this study's preprint [@doi:10.7287/peerj.preprints.3100v1], Sci-Hub [tweeted](https://twitter.com/Sci_Hub/status/892751909530071040): "the information on donations … is not very accurate, but I cannot correct it: that is confidential."
Therefore, presumably, Sci-Hub has received considerable donations via alternative payment systems or to unrevealed Bitcoin addresses, which our audit did not capture.

![
**Number of bitcoin donations per month.**
The number of bitcoin donations to Sci-Hub is shown for each month from June 2015 to August 2017.
Since February 2016, Sci-Hub has received over 25 donations per month.
Each donation corresponds to an incoming transaction to a known Sci-Hub address.
](https://cdn.rawgit.com/greenelab/scihub/6c6d19a56a0371afe6131c7948c406f256b8742c/explore/bitcoin/monthly-donations-count.svg){#fig:bitcoin}

The largest, most prominent academic publishers are thoroughly covered by Sci-Hub, and these publishers have taken note.
Elsevier (whose 13 million works are 97.3% covered by Sci-Hub) and the American Chemical Society (whose 1.4 million works are 98.8% covered) have both filed suit against Sci-Hub, despite the limited enforcement options of United States courts.
The widespread gratis access that Sci-Hub provides to previously paywalled articles calls into question the sustainability of the subscription publishing model [@doi:10.1629/uksg.333; @doi:10.1126/science.aan7164].
As distributed and censorship-resistant file storage protocols mature [@arxiv:1407.3561v1; @url:https://media.consensys.net/decentralized-storage-the-backbone-of-the-third-web-d4bc54e79700], successors to Sci-Hub may emerge that no longer rely on a centralized service.
Indeed, Alexandra Elbakyan is only one individual in the larger "guerilla access" movement [@doi:10.2139/ssrn.2816925; @doi:10.2139/ssrn.2616636; @url:http://www.atlasobscura.com/articles/the-rise-of-illegal-pirate-libraries], which will persist regardless of Sci-Hub's fate.
As such, Sci-Hub's corpus of gratis scholarly literature may be extremely difficult to suppress.

In addition, adoption of Sci-Hub and similar sites may accelerate if universities continue canceling increasingly expensive journal subscriptions [@doi:10.1038/nature.2016.21223; @doi:10.1126/science.aal0552; @doi:10.6084/m9.figshare.1186832.v23; @doi:10.6084/m9.figshare.4542433.v6], leaving researchers with few alternative access options [@url:https://scholarlykitchen.sspnet.org/2017/09/05/sci-hub-moves-center-ecosystem/].
We can also expect biblioleaks — bulk releases of closed access corpuses — to progress despite publisher's best efforts, as articles must only leak once to be perpetually available [@doi:10.2196/jmir.3331].
In essence, scholarly publishers have already lost the access battle.
Publishers will be forced to adapt quickly to open access publishing models.
In the words of Alexandra Elbakyan [@url:https://engineuring.wordpress.com/2016/02/24/why-sci-hub-is-the-true-solution-for-open-access-reply-to-criticism/]:

> The effect of long-term operation of Sci-Hub will be that publishers change their publishing models to support Open Access, because closed access will make no sense anymore.

Sci-Hub is poised to fundamentally disrupt scholarly publishing.
The transition to gratis availability of scholarly articles is currently underway, and such a model may be inevitable in the long term.
However, we urge the community to take this opportunity to fully liberate scholarly articles, as well as explore more constructive business models for publishing [@doi:10.3233/978-1-61499-769-6-118; @doi:10.1126/science.aap7562].
Only libre access, enabled by [open licensing](http://opendefinition.org/), allows building applications on top of scholarly literature without fear of legal consequences [@url:http://blog.dhimmel.com/biorxiv-licenses/].
For example, fulltext mining of scholarly literature is an area of great potential [@doi:10.1101/162099], but is currently impractical due to the lack of a large-scale preprocessed corpus of articles.
The barriers here are legal, not technological [@doi:10.1045/november14-brook; @doi:10.1038/483134a].
In closing, were all articles libre, there would be no such thing as a "pirate website" for accessing scholarly literature.

## Methods {.page_break_before}

This project was performed entirely in the open, via the GitHub repository [`greenelab/scihub`](https://github.com/greenelab/scihub).
Several authors of this study became involved after we mentioned their usernames in GitHub discussions.
This project's fully transparent and online model enabled us to assemble an international team of individuals with complementary expertise and knowledge.

We managed our computational environment using [Conda](https://conda.io/docs/), allowing us to specify and install dependencies for both Python and R.
We performed our analyses using a series of [Jupyter](http://jupyter.org/) notebooks.
In general, data integration and manipulation were performed in Python 3, relying heavily on [Pandas](https://pandas.pydata.org/), while plotting was performed with [ggplot2](http://ggplot2.org/) in R.
Tabular data were saved in TSV (tab-separated values) format, and large datasets were compressed using [XZ](https://tukaani.org/xz/).
We used Git Large File Storage ([Git LFS](https://git-lfs.github.com/)) to track large files, enabling us to make nearly all of the datasets generated and consumed by the analyses available to the public.
The Sci-Hub Stats Browser is a single-page application built using React and hosted via GitHub Pages.

The manuscript source for this study is located at [`greenelab/scihub-manuscript`](https://github.com/greenelab/scihub-manuscript).
We used the [Manubot Rootstock](https://github.com/greenelab/manubot-rootstock) system to automatically generate the manuscript from Markdown files.
This system — originally developed for the [Deep Review](https://github.com/greenelab/deep-review) to enable collaborative writing on GitHub [@doi:10.1101/142760] — uses continuous analysis to fetch reference metadata and rebuild the manuscript upon changes [@doi:10.1038/nbt.3780].

### Digital Object Identifiers

We used DOIs (Digital Object Identifiers) to uniquely identify articles.
Sci-Hub and LibGen's scimag repository also uniquely identify articles by their DOIs, making DOIs the natural primary identifier for our analyses.
The DOI initiative began in 1997, and the first DOIs were registered in 2000 [@doi:10.1000/182; @doi:10.1016/j.serrev.2007.05.006].
Note that DOIs can be registered retroactively.
For example, Antony van Leewenhoeck's discovery of protists and bacteria — published in 1677 by _Philosophical Transactions of the Royal Society of London_ [@doi:10.1098/rstl.1677.0003] — has a DOI (`10.1098/rstl.1677.0003`).
While van Leewenhoeck's article was published long before the DOI system existed, the _Royal Society_ retroactively assigned it a DOI in 2006.

Not all scholarly articles have DOIs.
By evaluating the presence of DOIs in other databases of scholarly literature (such as PubMed, Web of Science, and Scopus), researchers estimate around 90% of newly published articles in the sciences have DOIs [@doi:10.1016/j.joi.2015.11.008; @doi:10.1007/s11192-016-2225-6].
The prevalence of DOIs varies by discipline and country of publication, with DOI assignment in newly published Arts & Humanities articles around 60% [@doi:10.1016/j.joi.2015.11.008].
Indeed, DOI registration is almost entirely lacking for publishers from many Eastern European countries [@doi:10.1007/s11192-016-2225-6].
In addition, the prevalence of DOI assignment is likely lower for older articles [@doi:10.1007/s11192-016-2225-6].
The incomplete and non-random assignment of DOIs to scholarly articles is a limitation of this study.
However, DOIs are presumably the least imperfect and most widespread identifier for scholarly articles.

An often overlooked aspect of the DOI system is that DOIs are case-insensitive within the ASCII character range [@doi:10.1000/182; @doi:10.3403/30177056].
In other words, `10.7717/peerj.705` refers to the same article as `10.7717/PeerJ.705`.
Accordingly, DOIs make a poor standard identifier unless they are consistently cased.
While the DOI handbook states that "all DOI names are converted to upper case upon registration" [@doi:10.1000/182], we lowercased DOIs in accordance with Crossref's behavior.
Given the risk of unmatched DOIs, we lowercased DOIs for each input resource at the earliest opportunity in our processing pipeline.
Consistent casing [considerably influenced](https://github.com/greenelab/scihub/issues/9) our findings as different resources used different casings of the same DOI.

### Crossref-derived catalog of scholarly articles

To catalog all scholarly articles, we relied on the Crossref database.
[Crossref](https://www.crossref.org/) is a DOI Registration Agency (an entity capable of assigning DOIs) for scholarly publishing [@doi:10.6087/kcse.2014.1.13].
There are presently 10 Registration Agencies.
We [estimate](https://github.com/greenelab/crossref/issues/3) that Crossref has registered 67% of all DOIs in existence.
While several Registration Agencies assign DOIs to scholarly publications, Crossref is the preeminent registrar.
In March 2015, of the 1,464,818 valid DOI links on the English version of Wikipedia, 99.9% were registered with Crossref [@doi:10.1007/978-3-319-49304-6_40].
This percentage was slightly lower for other languages: 99.8% on Chinese Wikipedia and 98.0% on Japanese Wikipedia.
Hence, the overwhelming majority of DOI-referenced scholarly articles are registered with Crossref.
Since Crossref has the most comprehensive and featureful programmatic access, there was a strong incentive to focus solely on Crossref-registered DOIs.
Given Crossref's preeminence, the omission of other Registration Agencies is unlikely to significantly influence our findings.

We queried the `works` endpoint of the [Crossref API](https://api.crossref.org/) to retrieve the metadata for all DOIs, storing the responses in a MongoDB database.
The queries began on March 21, 2017 and took 12 days to complete.
In total, we retrieved metadata for 87,542,370 DOIs, corresponding to all Crossref works as of March 21, 2017.
The source code for this step is available on GitHub at [`greenelab/crossref`](https://github.com/greenelab/crossref).
Due to its large file size (7.4 GB), the MongoDB database export of DOI metadata is not available on GitHub, and is instead hosted via figshare [@doi:10.6084/m9.figshare.4816720.v1].
We created TSV files with the minimal information needed for this study:
First, a DOI table with columns for work type and date issued.
Date issued refers to the earliest known publication date, i.e. the date of print or online publication, whichever occurred first.
Second, a mapping of DOI to ISSN for associating articles with their journal of publication.

We [selected](https://github.com/greenelab/scihub/issues/7) a subset of Crossref work types to include in our Sci-Hub coverage analyses that corresponded to scholarly articles (i.e. publications).
Since we could not locate definitions for the Crossref types, we used our best judgment and evaluated sample works of a given type in the case of uncertainty.
We included the following types: `book-chapter`, `book-part`, `book-section`, `journal-article`, `proceedings-article`, `reference-entry`, `report`, and `standard`.
Types such as `book`, `journal`, `journal-issue`, and `report-series` were excluded, as they are generally containers for individual articles rather than scholarly articles themselves.
After filtering by type, 81,609,016 DOIs remained (77,201,782 of which had their year of publication  available).
For the purposes of this study, these DOIs represent the entirety of the scholarly literature.

### Scopus-derived catalog of journals

Prior to June 2017, the Crossref API had an [issue](https://github.com/CrossRef/rest-api-doc/issues/179) that prevented exhaustively downloading journal metadata.
Therefore, we instead relied on the [Scopus](https://www.scopus.com) database to catalog scholarly journals.
Scopus uses "title" to refer to all of the following: peer-reviewed journals, trade journals, book series, and conference proceedings.
For this study, we refer to all of these types as journals.
From the January 2017 data release of Scopus titles, we extracted metadata for 62,482 titles including their names, ISSNs, subject areas, open access status, and active status.
This version of Scopus based open access status on whether a journal was registered in [DOAJ](https://doaj.org/) or [ROAD](http://road.issn.org/) as of March 2016.
Note that Scopus does not index every scholarly journal [@doi:10.1007/s11192-015-1765-5], which is one reason why 30.1% of articles (24,534,808 DOIs) were not attributable to a journal.

We tidied the Scopus Journal Metrics, which evaluate journals based on the number of citations their articles receive.
Specifically, we extracted a 2015 CiteScore for 22,256 titles, 17,295 of which were included in our journal catalog.
Finally, we queried the Elsevier API to [retrieve](https://github.com/dhimmel/journalmetrics/issues/2) homepage URLs for 20,442 Scopus titles.
See [`dhimmel/journalmetrics`](https://github.com/dhimmel/journalmetrics) for the source code and data relating to Scopus.

### LibGen scimag's catalog of articles

Library Genesis (LibGen) is a shadow library primarily comprising illicit copies of academic books and articles.
Compared to Sci-Hub, the operations of LibGen are more opaque, as the contributors maintain a low profile and do not contact journalists [@url:https://engineuring.wordpress.com/2017/07/02/some-facts-on-sci-hub-that-wikipedia-gets-wrong/].
LibGen hosts several collections, including distinct repositories for scientific books and textbooks, fiction books, and comics [@doi:10.1002/asi.23445].
In 2012, LibGen added the "scimag" database for scholarly literature.
Since the spring of 2013, Sci-Hub has uploaded articles that it obtains to LibGen scimag [@url:https://engineuring.wordpress.com/2017/07/02/some-facts-on-sci-hub-that-wikipedia-gets-wrong/].
At the end of 2014, Sci-Hub forked LibGen scimag and began managing its own distinct article repository.

We downloaded the LibGen scimag metadata database on April 7, 2017 as a SQL dump.
We [imported](https://github.com/greenelab/scihub/issues/2) the SQL dump into MySQL, and then exported the scimag table to a TSV file [@doi:10.6084/m9.figshare.5231245.v1].
Each row of this table corresponds to an article in LibGen, identified by its DOI.
The `TimeAdded` field apparently indicates when the publication was uploaded to LibGen.
After removing records missing `TimeAdded`, 64,195,940 DOIs remained.
56,205,763 (87.6%) of the DOIs were in our Crossref-derived catalog of scholarly literature.
The 12.4% of LibGen scimag DOIs missing from our Crossref catalog likely comprise incorrect DOIs, DOIs whose metadata availability postdates our Crossref export, DOIs from other Registration Agencies, and DOIs for excluded publication types.

Next, we explored the cumulative size of LibGen scimag over time according to the `TimeAdded` field (Figure @fig:libgen-size).
However, when we [compared](https://github.com/greenelab/scihub/issues/8#issuecomment-296710357) our plot to one generated from the LibGen scimag database SQL dump on January 5, 2014 [@doi:10.1002/asi.23445; @doi:10.6084/m9.figshare.4906367.v1], we noticed a major discrepancy.
The earlier analysis identified a total of 22,829,088 DOIs, whereas we found only 234,504 DOIs as of January 5, 2014.
We hypothesize that the discrepancy arose because `TimeAdded` indicates the date modified rather than created.
Specifically, when an article in the database is changed, the database record for that DOI is entirely replaced.
Hence, the `TimeAdded` value is effectively overwritten upon every update to a record.
Unfortunately, many research questions require the date first added.
For example, lag-time analyses (the time from study publication to LibGen upload) may be unreliable.
Therefore, we do not report on these findings in this manuscript.
Instead, we provide Figure @fig:libgen-lag as an example analysis that would be highly informative were reliable creation dates available.
In addition, findings from some previous studies may require additional scrutiny.
For example, Cabanac writes [@doi:10.1002/asi.23445]:

> The growth of LibGen suggests that it has benefited from a few isolated, but massive, additions of scientific articles to its cache.
For instance, 71% of the article collection was uploaded in 13 days at a rate of 100,000+ articles a day.
It is likely that such massive collections of articles result from biblioleaks [@doi:10.2196/jmir.3331], but one can only speculate about this because of the undocumented source of each file cached at LibGen.

While we agree this is most likely the case, confirmation is needed that the bulk addition of articles does not simply correspond to bulk updates rather than bulk initial uploads.

### Sci-Hub's catalog of articles

On March 19, 2017, Sci-Hub [tweeted](https://twitter.com/Sci_Hub/status/843546352219017218):

> If you like the list of all DOI collected on Sci-Hub, here it is: `sci-hub.cc/downloads/doi.7z` … 62,835,101 DOI in alphabetical order

The Tweet included a download link for a file with the 62,835,101 DOIs that Sci-Hub claims to provide access to.
Of these DOIs, 56,246,220 were part of the Crossref-derived catalog of scholarly articles.
99.5% of the DOIs from Sci-Hub's list were in the LibGen scimag repository (after filtering).
Hence, the LibGen scimag and Sci-Hub repositories have largely stayed in sync since their split.
On Twitter, the Sci-Hub account confirmed this finding, [commenting](https://twitter.com/Sci_Hub/status/844165613203480576) "with a small differences, yes the database is the same".
Therefore, the LibGen scimag and Sci-Hub DOI catalogs can essentially be used interchangeably for research purposes.

### State of OA Datasets

[oaDOI](https://oadoi.org/), short for open access DOI, is a service that determines whether a DOI is available gratis somewhere online [@doi:10.7287/peerj.preprints.3119v1; @url:http://blog.impactstory.org/introducting-oadoi/].
oaDOI does not index articles posted to academic social networks or available from illicit repositories such as Sci-Hub [@doi:10.7287/peerj.preprints.3119v1].
Using the oaDOI infrastructure, @doi:10.7287/peerj.preprints.3119v1 investigated the availability of articles from three collections [@doi:10.5281/zenodo.837902].
Each collection consists of a random sample of approximately 100,000 articles from a larger corpus.
We describe the collections below and report the number of articles after intersection with our DOI catalog:

+ **Web of Science**: 103,491 articles published between 2009–2015 and classified as citable items in Web of Science.
+ **Unpaywall**: 87,322 articles visited by Unpaywall users from June 5–11, 2017.
+ **Crossref**: 99,952 articles with Crossref type of `journal-article`.

[Unpaywall](http://unpaywall.org/) is a web-browser extension that notifies its user if an article is available via oaDOI [@doi:10.1038/nature.2017.21765].
Since the Unpaywall collection is based on articles that users visited, it's a better reflection of the actual access needs of contemporary scholars.
Unfortunately, since the number of visits per article is not preserved by this dataset, fulfillment rate estimates are biased against highly-visited articles and become scale-variant (affected by the popularity of Unpaywall).
Nonetheless, the Unpaywall collection is the best benchmark we have for which articles scholars actually visit.

@doi:10.7287/peerj.preprints.3119v1 ascertained the accessibility status of each DOI in each collection using oaDOI [@doi:10.5281/zenodo.837902].
Articles for which oaDOI did not identify a full-text were considered "closed".
Otherwise, articles were assigned a color/status of bronze, green, hybrid, or gold [@doi:10.7287/peerj.preprints.3119v1].

### Recent citation catalog

[OpenCitations](http://opencitations.net) is an public domain resource containing scholarly citation data [@doi:10.1108/JD-12-2013-0166].
OpenCitations extracts its information from the Open Access Subset of PubMed Central.
In the [`greenelab/opencitations`](https://github.com/greenelab/opencitations) repository, we processed the July 25, 2017 OpenCitations data release [@doi:10.6084/m9.figshare.3443876.v3 @doi:10.6084/m9.figshare.5255365.v1; @doi:10.6084/m9.figshare.5255368.v1], creating a DOI–cites–DOI catalog of bibliographic references.
For quality control, we removed DOIs that were not part of the Crossref-derived catalog of articles.
Furthermore, we removed outgoing citations from articles published before 2015.
Incoming citations to articles predating 2015 were not removed.
The resulting catalog consisted of 7,312,607 citations from 200,206 recent articles to 3,857,822 referenced articles.

### Sci-Hub access logs

The 2016 study titled "Who's downloading pirated papers? Everyone" analyzed a dataset of Sci-Hub access logs [@doi:10.1126/science.352.6285.508; @doi:10.1126/science.aaf5664].
Alexandra Elbakyan worked with journalist John Bohannon to produce a dataset of Sci-Hub's resolved requests from September 1, 2015 through February 29, 2016 [@doi:10.5061/dryad.q447c/1].
In November 2015, Sci-Hub's domain name was suspended as the result of legal action by Elsevier [@url:https://torrentfreak.com/sci-hub-and-libgen-resurface-after-being-shut-down-151121/; @doi:10.1038/nature.2015.18876].
According to Bohannon, this resulted in "an 18-day gap in the data starting November 4, 2015 when the domain `sci-hub.org` went down and the server logs were improperly configured."
We show this downtime in Figure @fig:history.

We filtered the access events by excluding DOIs not included in our literature catalog and omitting records that occurred before an article's publication date.
This filter preserved 26,984,851 access events for 10,293,836 distinct DOIs (97.5% of the 10,552,418 distinct prefiltered DOIs).

We summarized the access events for each article using the following metrics:

1. downloads: total number of times the article was accessed
2. visitors: number of IP addresses that accessed the article
3. countries: number of countries (geolocation by IP address) from which the article was accessed
4. days: number of days on which the article was accessed
5. months: number of months in which the article was accessed

Next, we calculated journal-level access metrics based on articles published from January 1, 2014 until the start of the Sci-Hub access log records on September 1, 2015.
For each journal, we calculated the average values for the five access log metrics described above.
Interestingly, the journal [_Medicine - Programa de Formación Médica Continuada Acreditado_](http://www.sciencedirect.com/science/journal/03045412) received the most visitors per article, averaging 33.4 visitors for each of its 326 articles.

## Supplementary Information

![
**Coverage by country of publication.**
Scopus assigns each journal a country of publication.
Sci-Hub's coverage is shown for countries with at least 100,000 articles.
](https://cdn.rawgit.com/greenelab/scihub/6c6d19a56a0371afe6131c7948c406f256b8742c/figure/coverage-by-country.svg){#fig:countries tag="S1"}

![
**Bitcoin donations to Sci-Hub per month.**
For months since June 2015, total bitcoin donations (deposits to known Sci-Hub addresses) are assessed.
Donations in USD refers to the United States dollar value at time of transaction confirmation.
](https://cdn.rawgit.com/greenelab/scihub/6c6d19a56a0371afe6131c7948c406f256b8742c/explore/bitcoin/monthly-donations-faceted.svg){#fig:bitcoin-all tag="S2"  width="5in"}

![
**Number of articles in LibGen scimag over time.**
The figure shows the cumulative number of articles versus the LibGen scimag `TimeAdded` field.
When comparing this plot to Figure 1 of Cabanac 2015 [@doi:10.1002/asi.23445], we noticed a major discrepancy.
We hypothesize that the `TimeAdded` field is replaced upon modification, making it impossible to assess date of first upload.
](https://cdn.rawgit.com/greenelab/scihub/6c6d19a56a0371afe6131c7948c406f256b8742c/figure/libgen-cumulative-works.svg){#fig:libgen-size tag="S3" width="4in"}

![
**Lag-time from publication to LibGen upload.**
For each year of publication from 2010–2017, we plot the relationship between lag-time and LibGen scimag's coverage.
For example, this plot shows that 75% of articles published in 2011 were uploaded to LibGen within 60 months.
This analysis only considers articles for which a month of publication can reliably be extracted, which excludes all articles that are allegedly published on the first day of each year.
This plot portrays lag-times as decreasing over time, with maximum coverage declining.
For example, coverage for 2016 articles exceeded 50% within 6 months, but appears to have reached an asymptote around 60%.
Alternatively, coverage for 2014 took 15 months to exceed 50%, but has since reached 75%.
However, this signal could result from post-dated LibGen upload timestamps.
Therefore, we caution against drawing any conclusions from the `TimeAdded` field in LibGen scimag until its accuracy can be established more reliably.
](https://cdn.rawgit.com/greenelab/scihub/7891082161dbcfcd5eeb1d7b76ee99ab44b95064/figure/libgen-monthly-lagtimes.svg){#fig:libgen-lag tag="S4"}
